对于ARM64架构来说，目前基于ARMv8-A架构的处理器最大可以支持到48根地址线，也就是寻址到2^48的虚拟地址空间，即虚拟地址空间0x000_0000_0000_0000~0x0000_FFFF_FFFF_FFFF，共256TB。理论上完全可以做到64根地址线，那么最大寻址空间也就有了2^64的虚拟地址空间。但是对于目前应用来说，256TB的虚拟地址空间已经足够使用了，因为如果支持64位虚拟地址空间，意味着处理器设计需要考虑更多的地址线，CPU的设计难度也会变得更大；

基于ARMv8-A架构下的处理器的虚拟地址分为两个区域。一个是从0x0000_0000_0000_0000到0x0000_FFFF_FFFF_FFFF，另外一个是从0xFFFF_0000_0000_0000到0xFFFF_FFFF_FFFF_FFFF。

基于ARMv8-A架构下的处理器可以通过配置CONFIG_ARM64_VA_BITS这个宏来设置虚拟地址的宽度；

```
[arm/arm64/Kconfig]
config ARM64_VA_BITS
	int 
	default 39 if ARM64_VA_BITS_39
	default 42 if ARM64_VA_BITS_42
	default 48 if ARM64_VA_BITS_48
```

另外基于ARMv8-A架构下的处理器支持的最大物理地址宽度也是48位；

Linux内存空间布局与地址映射的粒度和地址映射的层数有关。基于ARMv8-A架构的处理器支持的层数为4KB、16KB或者64KB。映射的层级可以是3级或者4级；

下面是页面大小为4KB，地址宽度为48位，4级映射的内存分布图：

![](..\picture\4级映射内存分布图.png)下面是页面大小为4KB，地址宽度为48位，3级映射的内存分布图：

![3级映射内存分布图](..\picture\3级映射内存分布图.png)

Linux内核的documentation/arm64/memory.txt文件中还有其他不同配置的内存分布图；

我们的QEMU实验平台配置4KB大小页面，48位地址宽度，4级映射，下面以此为蓝本介绍ARM64映射过程：

如图2.5所示，地址转换过程如下：

![](..\picture\基于ARMv8-A架构的处理器的虚拟地址查找.png)

**(1)如果输入的虚拟地址最高位bit[63]为1，那么这个地址是用于内核空间的，页表的基地址寄存器用TTBR1_EL1（Translation Table Base Register 1）。如果bit[63]等于0，那么这个虚拟地址属于用户空间，页表基地址寄存器用TTBR0_EL1。**

**（2）TTBRx寄存器保存了第0级页表的基地址（L0 Table Base address，linux内核中称为PGD），L0页表中有512个表项（Table Descriptor），以虚拟地址的bit[47:39]作为索引值在L0页表中查找相应的表项。每个表项的内容都含有下一级页表的基地址，即L1页表（linux内核中称为PUD）的基地址；**

**（3）PUD页表中有512个表项，以虚拟地址的bit[38:30]为索引值在PUD表中查找相应的表项，每个表项的内容含有下一级页表的基地址，即L2页表（Linux内核中称为PMD）的基地址。**

**（4）PMD页表中有512个表项，以虚拟地址的bit[29:21]为索引值在PMD表中查找相应的表项，每个表项的内容都含有下一级页表的基地址，即L3页表（linux内核中称为PTE）的基地址；**

**（5）在PTE页表中，以虚拟地址的bit[20:12]为索引值在PTE表中查找相应的表项，每个PTE表项中含有最终的物理地址的bit[47:12]，和虚拟地址中bit[11:0]合并成最终的物理地址，完成地址翻译过程**



在内核初始化阶段会对内核空间的页表进行一一映射，实现的函数依然是create_mapping()。

```
static void __ref create_mapping(phys_addr_t phys, unsigned long virt,
				  phys_addr_t size, pgprot_t prot)
{
	if (virt < VMALLOC_START) {
		pr_warn("BUG: not creating mapping for %pa at 0x%016lx - outside kernel range\n",
			&phys, virt);
		return;
	}
	__create_mapping(&init_mm, pgd_offset_k(virt & PAGE_MASK), phys, virt,
			 size, prot, early_alloc);
}
```

首先会做虚拟地址的检查，低于VMALLOC_START的地址空间不是有效的内核虚拟地址空间。VMALLOC_START等于0xffff_0000_0000_0000。

PGD页表的基地址和ARM32内核一样，通过init_mm数据结构的pgd成员来获取，swapper_pg_dir全局变量指向PGD页表基地址；

```
[arch/arm64/kernel/vmlinux.lds.S]
	. = ALIGN(PAGE_SIZE);
	idmap_pg_dir = .;
	. += IDMAP_DIR_SIZE;
	swapper_pg_dir = .;
	. += SWAPPER_DIR_SIZE;
[arch/arm64/include/asm/page.h]
#define SWAPPER_PGTABLE_LEVELS	(CONFIG_ARM64_PGTABLE_LEVELS)

```



```\
[start_kernel -> setup_arch -> paging_init -> map_mem -> _map_memblock -> create_mapping]

/*
 * Create the page directory entries and any necessary page tables for the
 * mapping specified by 'md'.
 */
static void  __create_mapping(struct mm_struct *mm, pgd_t *pgd,
				    phys_addr_t phys, unsigned long virt,
				    phys_addr_t size, pgprot_t prot,
				    void *(*alloc)(unsigned long size))
{
	unsigned long addr, length, end, next;

	addr = virt & PAGE_MASK;
	length = PAGE_ALIGN(size + (virt & ~PAGE_MASK));

	end = addr + length;
	do {
		next = pgd_addr_end(addr, end);
		alloc_init_pud(mm, pgd, addr, next, phys, prot, alloc);
		phys += next - addr;
	} while (pgd++, addr = next, addr != end);
}
```

下面看下alloc_init_pud()函数

